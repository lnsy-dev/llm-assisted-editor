<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="LLM Editor.">
  <meta name="keywords" content="Vanilla JS, CSS, boilerplate, library, LNSY">
  <meta name="author" content="LNSY">
  <meta name="robots" content="index, follow">
  <!-- Open Graph meta tags for better sharing on social media -->
  <meta property="og:title" content="Vanilla JS / CSS boilerplate">
  <meta property="og:description" content="Vanilla JS / CSS boilerplate for generating JS and CSS libraries in plain CSS, JS, and HTML. Created by LNSY.">
  <meta property="og:image" content="./assets/splash.jpg">
  <meta property="og:url" content="https://example.com"> <!-- Replace with your actual URL -->
  <title>LLM Assisted Editor</title>
  <link rel="stylesheet" type="text/css" href="./editor/editor.css">
  <script src="./editor/editor.js" type="module"></script>
  <script type="module" src="./ai-generated.js"></script>
  <script type="module" src="https://lnsy-dev.github.io/markdown-component/dist/mark-down-component.min.js"></script>
  <style>
    body {
      display: flex;
      padding: 1em;
      margin: 0;
      font-family: var(--editor-font) !important;
    }

    input, button {
      box-sizing: border-box; /* Include padding and border in the element's total width and height */
      outline: none; /* Remove default outline */
    }

    lnsy-edit {
      flex: 1;
      height: 100%;

      details {
        padding: 1px;
      }
    }

    #llm_chat {
      flex: 1;
      font-family: var(--editor-font);
      padding: 0 1em;
      max-width: 50%;
    }

    #llm_response::-webkit-scrollbar {
      display: none;
    }

    #llm_response {
      height: 100%;
      padding-bottom: 14em;
      scrollbar-width: none; /* This hides the scrollbar */
      overflow: scroll;
      -ms-overflow-style: none;  /* For Internet Explorer and Edge */
      overflow-y: scroll; /* Vertical scrollbar will be hidden but the content is still scrollable */
    }

    #llm_question {
      color: var(--fg-color);
      background-color: transparent;
      width: 100%;
      clear: both;
    }
    #llm_question_container {
      width: calc(50% - 6em);
      height: 10em;
      position: fixed;
      bottom: 3em;
      right: 3em;
    }

    #open_ai_modal {
      position: fixed;
      width: 100%;
      height: 100%;
      left: 0px;
      top: 0px;
      z-index:100;
      background-color: rgba(0,0,0,0.9);
      display: none;
    }

    #open_ai_query {
      color: var(--bg-color);
      position: absolute;
      left: 50%;
      top: 50%;
      transform: translate(-50%, -50%);
      padding: 1em;
      border: 1px solid white;
    }

    #token_adjust {
      background-color: transparent;
      box-sizing: border;
      color: var(--fg-color);
      font-size: 10pt;
      padding: 2pt;
      border: 1px solid var(--mid-tone-color);
      position: relative;
      top: 1px;
      margin-left: 0.5em;
    }

    lnsy-edit summary {
      color: #224455;
    }

    #tokens-label {
      margin-left: 1em;
      font-size: 10pt;
      white-space: nowrap;
    }

    json-editor {
      display: none;
    }

    ai-generated {
      display: block;
      border: 1px solid var(--mid-tone-color);

      button {
        background-color: transparent;
        border: 1px solid var(--mid-tone-color);
        font-size: 80%;
        width: 100%;
      }

      mark-down {
        padding: 0.5em 1em 1em 1em;
        pre {
          white-space: break-spaces;
          margin: 0;
        }
      }

      header {
        width: 100%;
        font-size: 80%;
        font-style: italic;
        background-color: rgba(155,155,155,0.4);
      }
    }
  </style>
</head>
<body>

  <lnsy-edit id="md_editor"></lnsy-edit>


  <div id="llm_chat">
    <div id="llm_response">
    </div>
  </div>

  <script>
   const apiEndpoint = 'https://api.openai.com/v1/chat/completions';

   function updateLLMResponse(new_text){
    llm_response.innerHTML = new_text + llm_response.innerHTML;
   }

  async function queryLLM(promptText) {
    const apiKey = localStorage.getItem('open-ai-key'); 
    if(apiKey === null){
      open_ai_modal.style.display = 'block';
      return
    }

    const data = {
      max_tokens: parseInt(token_adjust.value),
      model: "gpt-3.5-turbo",
      messages: [
      {
        role: "system",
        content: "You are a helpful assistant."
      },
      {
        role: "user",
        content: promptText
      }]
    };

    try {
      const response = await fetch(apiEndpoint, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`
        },
        body: JSON.stringify(data),
      });

      const reader = response.body.getReader();
      let chunks = []; // Array to hold the chunks of data

      // Function to process the stream
      const processStream = async ({ done, value }) => {
        if (done) {
          console.log('Stream complete');
          const completeResponse = new TextDecoder("utf-8").decode(concatenate(chunks));
          console.log(completeResponse); // Process the complete response
          const parsed_response = JSON.parse(completeResponse);
          const response = `
            <ai-generated 
              model="${parsed_response.model}" 
              tokens-used="${parsed_response.usage.total_tokens}"
              content="${parsed_response.choices[0].message.content}">
            
            </ai-generated>
          `;
          loader_indicator.style.display = 'none'

          updateLLMResponse(response);
          return;
        }

        // Add the value (Uint8Array) to the chunks array
        chunks.push(value);

        // Read the next chunk
        return reader.read().then(processStream);
      };

      // Start reading the stream
      await reader.read().then(processStream);
    } catch (error) {
      console.error('Error calling OpenAI API:', error);
    }

  }

  // Helper function to concatenate Uint8Arrays
  function concatenate(arrays) {
    let totalLength = arrays.reduce((acc, value) => acc + value.length, 0);
    let result = new Uint8Array(totalLength);
    let length = 0;
    for(let array of arrays) {
      result.set(array, length);
      length += array.length;
    }
    return result;
  }



  md_editor.addEventListener('save', (e) => {
    e.preventDefault();
    const prompt = md_editor.getText();
    queryLLM(prompt);
    loader_indicator.style.display = 'block'

  });


    
  </script>

  <div id="loader_indicator">
    <style>

      #loader_indicator {
        position: fixed;
        left: 50%;
        top: 50%;
        transform: translate(-50%, -50%);
        display: none;
      }
      .lds-ellipsis {
        display: inline-block;
        position: relative;
        width: 80px;
        height: 80px;
      }
      .lds-ellipsis div {
        position: absolute;
        top: 33px;
        width: 13px;
        height: 13px;
        border-radius: 50%;
        background: var(--highlight-color);
        animation-timing-function: cubic-bezier(0, 1, 1, 0);
      }
      .lds-ellipsis div:nth-child(1) {
        left: 8px;
        animation: lds-ellipsis1 0.6s infinite;
      }
      .lds-ellipsis div:nth-child(2) {
        left: 8px;
        animation: lds-ellipsis2 0.6s infinite;
      }
      .lds-ellipsis div:nth-child(3) {
        left: 32px;
        animation: lds-ellipsis2 0.6s infinite;
      }
      .lds-ellipsis div:nth-child(4) {
        left: 56px;
        animation: lds-ellipsis3 0.6s infinite;
      }
      @keyframes lds-ellipsis1 {
        0% {
          transform: scale(0);
        }
        100% {
          transform: scale(1);
        }
      }
      @keyframes lds-ellipsis3 {
        0% {
          transform: scale(1);
        }
        100% {
          transform: scale(0);
        }
      }
      @keyframes lds-ellipsis2 {
        0% {
          transform: translate(0, 0);
        }
        100% {
          transform: translate(24px, 0);
        }
      }
    </style>
    <div class="lds-ellipsis"><div></div><div></div><div></div><div></div></div>
  </div>


  <style>
    #introduction_div {
      h2 {
        text-align: center;
      }

      ul {
        font-size: 80%;
      }


    }

    #open-ai-key-notification {
      margin-bottom: 0.5em;
    }

    #open-ai-key {
  display: flex; /* Enable flexbox */
  align-items: center; /* Align items vertically in the center */
  width: 100%; /* Take full width of the container */
}

#open-ai-key input[type="text"] {
  flex-grow: 1; /* Allow the input to grow and fill the space */
  margin-right: 8px; /* Add some space between input and submit button */
}

#open-ai-key input[type="submit"] {
  flex-shrink: 0; /* Prevent the button from shrinking */
  /* Width can be adjusted or removed to use the default width of the submit button */
}

  </style>
   <div id="open_ai_modal">
    <form id="open_ai_query">
      <div id="introduction_div">
        <h2>LLM Assisted Editor</h2>
        <ul>
        <li>This editor is for editing markdown files with an assist from Chat GPT 3.5</li>
        <li>Type your prompt into the editor on the left. Press Ctrl-S or press the Query button to query Chat GPT. </li>
        <li>To save the content of a query to the buffer, press the "Save to Buffer Button" on the response. This will add the LLM's response into your file.</li>
        <li>Adjust Tokens to change the length of the responses</li>
        </ul>
      </div>
      <div id="open-ai-key-notification">
        <p>
        <notification>This application requires an OpenAI API Key. You can create a new one <a href="https://platform.openai.com/api-keys" target="_blank">here</a>.</notification></p>
      </div>
      <div id="open-ai-key"><input placeholder="OpenAI Key" id="openai_key" autocomplete="off" type="text">
      <input type="submit"></div>
    </form>

    <script>

      let openaikey = localStorage.getItem('open-ai-key');
      if(openaikey === null || openaikey.length < 1){
        open_ai_modal.style.display = 'block';
      }

      open_ai_query.addEventListener('submit', (e) => {
        e.preventDefault();

        localStorage.setItem('open-ai-key', openai_key.value);
        open_ai_modal.style.display = 'none';
      })
    </script>

  </div>

</body>
</html>
